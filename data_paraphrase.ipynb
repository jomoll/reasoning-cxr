{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ef3f42bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from src.generate_gpt.call_gpt4 import call_gpt4v, call_gpt4_turbo\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import asyncio\n",
    "from multiprocessing import Pool\n",
    "from datasets import load_dataset, Dataset\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ddde431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PARAPHRASES = 5\n",
    "NUM_SAMPLES = 100\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are a practicing radiologist rewriting reasoning steps in JSON form.\n",
    "- Preserve the exact clinical meaning and assessment.\n",
    "- Keep the same JSON structure and field names.\n",
    "- Maintain the “Action” field as a list of concise, present-tense sentences—each one describing a single micro-step.  \n",
    "  • You may reorder, merge, or split action steps without changing meaning. Below are examples of merging and splitting the Action list.  \n",
    "    Example A (merged, 2 steps):  \n",
    "    Original:  \n",
    "    \"Action\": [\"Inspect the cardiac silhouette.\", \"Confirm enlargement.\", \"Verify sharp borders.\"]\n",
    "    Paraphrased:\n",
    "    \"Action\": [\"Examine the cardiac silhouette and note enlargement with sharp borders.\"]\n",
    "\n",
    "    Example B (split, 4 steps):\n",
    "    Original:\n",
    "    \"Action\": [\"Assess mediastinal size and position.\", \"Check border clarity.\"]\n",
    "    Paraphrase:\n",
    "    \"Action\": [\n",
    "      \"Evaluate mediastinal width relative to thoracic cavity.\",\n",
    "      \"Confirm midline alignment of the mediastinum.\",\n",
    "      \"Inspect the contours for sharpness.\",\n",
    "      \"Note any irregularities in border definition.\"\n",
    "    ]\n",
    "  • Vary your choice of verbs (e.g. Examine, Review, Scan, Inspect) and sentence structures.\n",
    "- Use realistic radiology terminology appropriate to each finding (e.g. “cardiac silhouette” instead of “heart size,” “cardiomegaly” where applicable).\n",
    "- Paraphrase the “Description” and “Result” fields in concise clinical statements:\n",
    "  • Description must start with an imperative verb (Assess, Inspect, Evaluate) and specify the task.  \n",
    "  • Result must summarize the key finding using a noun phrase (e.g. “Findings consistent with…”, “Evidence of…”, “No evidence of…”).\n",
    "- Produce linguistically diverse variants—avoid repeating the same phrasing across paraphrases.\n",
    "- Do not add, remove, or alter any findings.\n",
    "\n",
    "\n",
    "Paraphrase this step:\n",
    "{step_json}\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c5e08e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = \"jomoll/TAIX-reasoning-v2.1-cleaned-stepwise-filtered\"\n",
    "dataset = load_dataset(input_dataset, split=\"train\")\n",
    "# only use the first 10 samples for now\n",
    "dataset = dataset.select(range(NUM_SAMPLES))\n",
    "output_dataset = \"jomoll/TAIX-reasoning-v2.1-cleaned-stepwise-filtered-paraphrased\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "250f584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_paraphrase(step_json):\n",
    "    \"\"\"\n",
    "    Generate a paraphrase for a single reasoning step using GPT-4.\n",
    "    \"\"\"\n",
    "    prompt = PROMPT_TEMPLATE.format(step_json=step_json)\n",
    "    cost, response = await call_gpt4_turbo(\"\",prompt, temperature=0.5)\n",
    "    return response\n",
    "\n",
    "async def process_sample(sample):\n",
    "    step_json = json.dumps(sample[\"Reasoning\"][0][\"Step\"])\n",
    "    paraphrase = await generate_paraphrase(step_json)\n",
    "    return json.loads(paraphrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a7f48b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paraphrasing: 100%|██████████| 100/100 [31:51<00:00, 19.12s/it]\n",
      "Map: 100%|██████████| 600/600 [00:00<00:00, 5478.33 examples/s]t/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 44.83ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushed 600 examples to jomoll/TAIX-reasoning-v2.1-cleaned-stepwise-filtered-paraphrased\n"
     ]
    }
   ],
   "source": [
    "new_rows = []\n",
    "for sample in tqdm(dataset, desc=\"Paraphrasing\"):\n",
    "    new_rows.append(copy.deepcopy(sample))  # Keep the original sample\n",
    "    for _ in range(NUM_PARAPHRASES):\n",
    "        result = await process_sample(sample)\n",
    "        new_sample = copy.deepcopy(sample)\n",
    "        new_sample[\"Reasoning\"][0][\"Step\"] = result\n",
    "        new_rows.append(new_sample)\n",
    "new_ds = Dataset.from_list(new_rows)\n",
    "new_ds.push_to_hub(output_dataset)\n",
    "print(f\"Pushed {len(new_ds)} examples to {output_dataset}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medgemma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
